# src/engines/openai_engine.py
"""
Wrapper de utilidades para la OpenAI Python >= 1.0.
Expone dos funciones:

    ‚Ä¢ fetch_response()    ‚Üí texto ‚Äúcrudo‚Äù del modelo
    ‚Ä¢ extract_insights()  ‚Üí JSON rico para dashboards

Todas las llamadas usan la nueva sintaxis v1 (`client.chat.completions.create`).
"""

from __future__ import annotations

import json
import logging
import os
from typing import Any, Dict, Tuple

from dotenv import load_dotenv
from openai import OpenAI, OpenAIError

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Funciones del Engine ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def fetch_response(
    prompt: str,
    *,
    model: str = "gpt-4o-mini",
    temperature: float = 0.3,
    max_tokens: int = 1_024,
) -> str:
    """
    Env√≠a un prompt y devuelve la respuesta textual del modelo.
    Usa gpt-4o-mini por defecto por ser r√°pido y econ√≥mico.
    """
    try:
        res = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Eres un analista especializado en educaci√≥n superior y captaci√≥n de alumnos. "
                        "Conoces a 'The Core School' en Madrid: escuela superior de entretenimiento y artes audiovisuales "
                        "(cine, videojuegos, animaci√≥n, producci√≥n). Prioriza exactitud, JSON v√°lido y contexto de negocio."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            temperature=temperature,
            max_tokens=max_tokens,
        )
        answer: str = res.choices[0].message.content.strip()
        return answer
    except OpenAIError as exc:
        logger.exception("‚ùå OpenAI API error en fetch_response: %s", exc)
        raise


def extract_insights(text: str) -> Dict[str, Any]:
    """
    Analiza el CONTENIDO y devuelve un JSON listo para la tabla `insights`.
    Utiliza un modelo m√°s potente (gpt-4o) para asegurar alta calidad en el an√°lisis.
    """
    prompt = f"""
Contexto de Negocio: Est√°s analizando datos para 'The Core School', escuela superior en Madrid, especializada en
entretenimiento y artes audiovisuales (cine, videojuegos, animaci√≥n, producci√≥n). Interpreta las consultas pensando en
captaci√≥n de alumnos, reputaci√≥n de marca y posicionamiento en el sector educativo.

Eres un **analista senior de inteligencia de mercado**.

1Ô∏è‚É£ Lee atentamente el CONTENIDO.
2Ô∏è‚É£ Identifica **todas las MARCAS o productos** citados.
3Ô∏è‚É£ Cuenta cu√°ntas veces aparece cada marca.
4Ô∏è‚É£ Eval√∫a el **sentimiento promedio** hacia cada marca (‚àí1 a 1).
5Ô∏è‚É£ Detecta **competidores** relevantes.
6Ô∏è‚É£ Extrae **insights accionables** en: opportunities, risks, pain_points, trends.
7Ô∏è‚É£ A√±ade **hasta 3 QUOTES** literales (‚â§ 200 caracteres) que representen el tono.
8Ô∏è‚É£ Identifica los temas m√°s importantes (top_themes) y su frecuencia (topic_frequency).
9Ô∏è‚É£ Si se citan dominios (ej. forbes.com), an√≥talos en source_mentions.
üîü Extrae "calls_to_action", p√∫blico objetivo (audience_targeting) y productos/features.

Devuelve SOLO un objeto **JSON** con este formato EXACTO:

{{
  "brands": [{{"name": "...", "mentions": <int>, "sentiment_avg": <float>}}],
  "competitors": ["...", "..."],
  "opportunities": ["...", "..."],
  "risks": ["...", "..."],
  "pain_points": ["...", "..."],
  "trends": ["...", "..."],
  "quotes": ["...", "..."],
  "top_themes": ["...", "..."],
  "topic_frequency": {{"keyword": <int>}},
  "source_mentions": {{"domain": <int>}},
  "calls_to_action": ["...", "..."],
  "audience_targeting": ["...", "..."],
  "products_or_features": ["...", "..."]
}}

No a√±adas texto fuera del JSON.
----------
CONTENIDO:
{text}
----------
"""
    # Usamos gpt-4o expl√≠citamente para la m√°xima calidad en el an√°lisis
    raw = fetch_response(prompt, model="gpt-4o", temperature=0.2, max_tokens=2048)
    try:
        # Intenta limpiar la respuesta si viene en un bloque de c√≥digo markdown
        if raw.startswith("```json"):
            raw = raw[7:-3].strip()
        data: Dict[str, Any] = json.loads(raw)
        return data
    except (json.JSONDecodeError, TypeError) as exc:
        logger.error("‚ùå Error extrayendo insights: %s\nRespuesta del modelo: %s", exc, raw)
        return {}


def fetch_response_with_metadata(
    prompt: str,
    *,
    model: str = "gpt-4o-mini",
    temperature: float = 0.3,
    max_tokens: int = 1_024,
) -> Tuple[str, Dict[str, Any]]:
    """
    Igual que fetch_response pero adem√°s devuelve metadatos √∫tiles para observabilidad.
    """
    try:
        res = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Eres un asistente √∫til. Sigue exactamente las instrucciones del usuario."},
                {"role": "user", "content": prompt},
            ],
            temperature=temperature,
            max_tokens=max_tokens,
        )
        answer = res.choices[0].message.content.strip()
        usage = getattr(res, "usage", None)
        input_tokens = getattr(usage, "prompt_tokens", None) if usage else None
        output_tokens = getattr(usage, "completion_tokens", None) if usage else None
        request_id = getattr(res, "id", None)
        meta: Dict[str, Any] = {
            "model_name": model,
            "api_status_code": 200,
            "engine_request_id": request_id,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
        }
        # Estimaci√≥n simple de coste (ajusta precios seg√∫n tu contrato)
        if input_tokens is not None and output_tokens is not None:
            # Ejemplo: 0.000005 por token in, 0.000015 por token out
            meta["price_usd"] = round(input_tokens * 0.000005 + output_tokens * 0.000015, 6)
        return answer, meta
    except OpenAIError as exc:
        logger.exception("‚ùå OpenAI API error en fetch_response_with_metadata: %s", exc)
        return "", {
            "model_name": model,
            "api_status_code": getattr(getattr(exc, "response", None), "status_code", None) or 500,
            "engine_request_id": None,
            "input_tokens": None,
            "output_tokens": None,
            "price_usd": None,
            "error_category": "api_error",
        }